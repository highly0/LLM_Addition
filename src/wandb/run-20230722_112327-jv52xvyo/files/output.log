  0%|                                                                        | 0/3750 [00:00<?, ?it/s]You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.












 13%|████████▎                                                     | 500/3750 [00:27<02:55, 18.50it/s]
 38%|████████████████████████▍                                       | 24/63 [00:00<00:00, 108.77it/s]
{'loss': 1.7473, 'learning_rate': 1.7333333333333336e-05, 'epoch': 0.67}














 26%|████████████████▎                                             | 987/3750 [00:56<02:28, 18.55it/s]

 27%|████████████████▎                                            | 1000/3750 [00:57<02:28, 18.51it/s]













 40%|████████████████████████▍                                    | 1500/3750 [01:26<02:01, 18.55it/s]
 38%|████████████████████████▍                                       | 24/63 [00:00<00:00, 108.26it/s]
{'loss': 1.1216, 'learning_rate': 1.2e-05, 'epoch': 2.0}















 53%|████████████████████████████████▌                            | 2000/3750 [01:56<01:34, 18.45it/s]
{'loss': 1.0785, 'learning_rate': 9.333333333333334e-06, 'epoch': 2.67}














 66%|████████████████████████████████████████▌                    | 2493/3750 [02:24<01:07, 18.53it/s]
{'loss': 1.0458, 'learning_rate': 6.666666666666667e-06, 'epoch': 3.33}














 80%|████████████████████████████████████████████████▊            | 3000/3750 [02:54<00:41, 18.25it/s]
 56%|███████████████████████████████████▌                            | 35/63 [00:00<00:00, 105.84it/s]
{'loss': 1.0358, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.0}















 93%|████████████████████████████████████████████████████████▉    | 3500/3750 [03:24<00:13, 18.37it/s]
{'loss': 1.0205, 'learning_rate': 1.3333333333333334e-06, 'epoch': 4.67}








100%|█████████████████████████████████████████████████████████████| 3750/3750 [03:39<00:00, 18.36it/s]
{'train_runtime': 222.2121, 'train_samples_per_second': 270.012, 'train_steps_per_second': 16.876, 'train_loss': 1.1696992268880209, 'epoch': 5.0}
100%|█████████████████████████████████████████████████████████████| 3750/3750 [03:42<00:00, 16.84it/s]
100%|████████████████████████████████████████████████████████████████| 63/63 [00:00<00:00, 100.82it/s]